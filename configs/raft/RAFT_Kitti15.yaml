data_cfg:
  name: KITTI2015
  root: data/Kitti2015
  train_list: datasets/KITTI15/kitti15_train200.txt
  val_list: datasets/KITTI15/kitti15_val35.txt
  test_list: datasets/KITTI15/kitti15_test.txt
  num_workers: 8
  train_batch_size: 4
  val_batch_size: 1
  pin_memory: true
  shuffle: true

  batch_uniform: true
#  random_type: range
#  w_range: [ 0.5, 2.0 ]
#  h_range: [ 0.5, 2.0 ]
  random_type: choice
  h_range: [ 256, 288, 320, 352 ]
  w_range: [ 480, 512, 544, 576 ]

  transform:
    train:
      - type: RandomCrop
        size: [ 256, 512 ]
#      - type: RandomHorizontalFlip
#        prob: 0.5
      - type: GetValidDisp
        max_disp: 192
      - type: TransposeImage
      - type: ToTensor
      - type: NormalizeImage
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]
    val:
      - type: CropOrPad
        size: [ 384, 1248 ]
      - type: GetValidDisp
        max_disp: 192
      - type: TransposeImage
      - type: ToTensor
      - type: NormalizeImage
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]
    test:
      - type: DivisiblePad
        by: 16
      - type: TransposeImage
      - type: ToTensor
      - type: NormalizeImage
        mean: [ 0.485, 0.456, 0.406 ]
        std: [ 0.229, 0.224, 0.225 ]


model_cfg:
  model: RAFT_Stereo

  base_config:
    hidden_dims: [128, 128, 128]
    n_gru_layers: 3
    n_downsample: 2
    slow_fast_gru: False
    max_disp: 192
    aug_params: []
    train_iters: 12
    corr_levels: 4
    corr_radius: 4
    shared_backbone: True
    corr_implementation: reg


loss_cfg:
  - log_prefix: disp
    loss_term_weight: 0.77  # 1/1.3
    type: Weighted_Smooth_l1_Loss
    weights: [ 1.0, 0.3 ]


trainer_cfg:
  save_name: RAFTStereo_Kitti15
  total_epoch: 1000
  restore_hint: '/mnt/cfs/algorithm/yiqun.duan/stereo/openstereo/output/SceneFlow/RAFT_Stereo/RAFT-Stereo_SceneFlow_newright/checkpoints/RAFT-Stereo_SceneFlow_newright_epoch_030.pt'
  resume: false
  optimizer_reset: true
  scheduler_reset: true
  warmup_reset: true
  log_iter: 1 # iter
  save_every: 50 # epoch
  val_every: 10 # epoch
  amp: true
  sync_bn: true
  fix_bn: false
  init_parameters: false

  optimizer_cfg:
    solver: Adam
    lr: 0.0008
    betas: [ 0.9, 0.999 ]
    lr_backbone: 0.0008
    lr_regression: 0.0016

  scheduler_cfg:
    scheduler: MultiStepLR
    gamma: 0.1
    milestones: [ 500, 800, 900 ]
    warmup:
      warmup_steps: 100

  evaluator_cfg:
    metric:
      - d1_all
      - epe
      - thres_1
      - thres_2
      - thres_3

  clip_grad_cfg:
    type: norm
    max_norm: 35
    norm_type: 2
